# BCM2835 "GPU_FFT" release 2.0
#
# Copyright (c) 2014, Andrew Holme.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#     * Redistributions of source code must retain the above copyright
#       notice, this list of conditions and the following disclaimer.
#     * Redistributions in binary form must reproduce the above copyright
#       notice, this list of conditions and the following disclaimer in the
#       documentation and/or other materials provided with the distribution.
#     * Neither the name of the copyright holder nor the
#       names of its contributors may be used to endorse or promote products
#       derived from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY
# DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
# ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

##############################################################################
# Macro baseline

.include "gpu_fft_ex.qinc"

##############################################################################
# Redefining some macros

.macro body_ra_save_64
    mov -, vw_wait

    .rep i, 7
        mov -, srel(i+1) # Master releases slaves
    .endr

    write_vpm_64

    # (MM) Optimized: prepare things before wait
    # (MM) Optimized: better use of both ALUs
    ;mov r0, 0x40 # joins with write_vpm_64
    mov r2, vdw_setup_0(1, 16, dma_h32(1,0)) - vdw_setup_0(1, 16, dma_h32(0,0)); mov r1, ra_save_ptr
    add ra_save_ptr, r1, r0;   mov r3, 30
    .assert countBits(PASS64_STRIDE) == 1 && PASS64_STRIDE >= 0x40
    shl.setf r3, r0, log2(PASS64_STRIDE) - log2(0x40); mov ra_temp, r3
    mov r0, vdw_setup_0(1, 16, dma_h32(0,0))

    .rep i, 7
        mov -, sacq(i+9) # Master waits for slaves
    .endr

    # (MM) Optimized: shorter code, slightly faster because of cache efficiency
:0  .rep i, 2
        add r0, r0, r2; mov vw_setup, r0
        add r1, r1, r3; mov vw_addr,  r1
    .endr
    .back 2
        brr.allnz -, r:0
        sub.setf ra_temp, ra_temp, 1
    .endb
    .rep i, 2
        add r0, r0, r2; mov vw_setup, r0
        add r1, r1, r3; mov vw_addr,  r1
    .endr
    .back 3
        bra -, ra_link_1
    .endb
.endm

# (MM) Optimized: do not replace macros by slower version
#.macro bit_rev
#.macro read_rev
